{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create the Master Data Table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This file creates a master table which combines all of the various data sources contained in the aws covid data lake, as well as the google mobility data.\n",
    "* https://aws.amazon.com/blogs/big-data/a-public-data-lake-for-analysis-of-covid-19-data/\n",
    "* Additional safegraph census data columns are available for selection in 'safegraph_census.ipynb'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd, pickle, boto3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Pipepline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Before using the aws related functions here, be sure to run 'aws configure' in your \n",
    "# virtual environment shell to set your ID and secret key\n",
    "\n",
    "def getS3Data(bucket, file_loc, csv=True):\n",
    "    client = boto3.client('s3')\n",
    "    obj = client.get_object(Bucket=bucket, Key=file_loc)\n",
    "    if(csv):\n",
    "        data = pd.read_csv(obj['Body'] , dtype=str)\n",
    "    else:\n",
    "        data = pd.read_json(obj['Body'])\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataCleanUp(data, date_field, fips_field, case_field, death_field, suffix): \n",
    "    print(\"Shape: \", data.shape)\n",
    "    data[fips_field] = data[fips_field].astype('str').apply(lambda x: x.zfill(5))\n",
    "    data[date_field] = data[date_field].astype('datetime64')\n",
    "    data[case_field] = data[case_field].astype('float64')\n",
    "    print(\"Case control total: \", data[case_field].sum())\n",
    "    data[death_field] = data[death_field].astype('float64')\n",
    "    print(\"Death control total: \", data[death_field].sum())\n",
    "    data = data.add_suffix(suffix)\n",
    "    data['date'] = data[date_field + suffix]\n",
    "    data = data.rename(str.lower, axis='columns') \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getDataInfo(data, case_field, death_field):\n",
    "    print(\"Dataframe Shape: \", data.shape)\n",
    "    print(\"Number of States: \", len(data['state_code'].unique()))\n",
    "    print(\"Number of Counties: \", len(data['fips_code'].unique()))\n",
    "    print(\"Minimum Date: \", data['date'].min())\n",
    "    print(\"Maximum Date: \", data['date'].max())\n",
    "    print(\"Duplicate State-Fips-Date: \", \n",
    "          data.groupby(['state_code','fips_code', 'date']).size().reset_index().rename(columns={0:'count'})['count'].sum() \n",
    "          - data.shape[0])\n",
    "    print(\"Null State Code: \", data[data.state_code.isnull()].size)\n",
    "    print(\"Null County Code: \", data[data.fips_code.isnull()].size)\n",
    "    print(\"Null Dates: \", enigma_agg_data[enigma_agg_data.date.isnull()].size)\n",
    "    \n",
    "    print(\"Case Control Total: \", data[case_field].sum())\n",
    "    print(\"Death Control Total: \", data[death_field].sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Static Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### County reference data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "Census Data\n"
     ]
    }
   ],
   "source": [
    "print(\"--------------------\")\n",
    "print(\"Census Data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get data\n",
    "county_ref_data = getS3Data('covid19-lake', 'static-datasets/csv/CountyPopulation/County_Population.csv')\n",
    "\n",
    "# Rename columns\n",
    "county_ref_data.columns = ['big_fips', 'fips', 'county', 'state', 'population_2018']\n",
    "\n",
    "# Fill leading zeros on fips code\n",
    "county_ref_data['fips'] = county_ref_data['fips'].astype('str').apply(lambda x: x.zfill(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### State reference data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get data\n",
    "state_ref_data = getS3Data('covid19-lake', 'static-datasets/csv/state-abv/states_abv.csv')\n",
    "\n",
    "# Rename columns\n",
    "state_ref_data.columns = ['state_name','state_code']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Safegraph Open Census Data\n",
    "* See notebook: 'safegraph_census.ipynb'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('safegraph_census.p', 'rb') as f:\n",
    "    safegraph_census_data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### FIPS Reference Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get data\n",
    "with open('safegraph_ref_data_fips.p', 'rb') as f:\n",
    "    safegraph_ref_data_fips = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Land area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get data\n",
    "with open('safegraph_land.p', 'rb') as f:\n",
    "    safegraph_land = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## COVID Cases and Deaths Timeseries Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Enigma Aggregation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Download data and cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "Enigma Aggregation\n"
     ]
    }
   ],
   "source": [
    "print(\"--------------------\")\n",
    "print(\"Enigma Aggregation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get data\n",
    "enigma_agg_data = getS3Data('covid19-lake', 'enigma-aggregation/csv/us_counties/enigma_covid_19_us_counties.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape:  (583062, 10)\n",
      "Case control total:  602329120.0\n",
      "Death control total:  22406363.0\n"
     ]
    }
   ],
   "source": [
    "# Clean up\n",
    "enigma_agg_data = dataCleanUp(enigma_agg_data, 'date', 'county_fips', 'cases','deaths','_ea')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change a few fips codes\n",
    "enigma_agg_data['fips_code'] = enigma_agg_data['county_fips_ea']\n",
    "enigma_agg_data.loc[enigma_agg_data['fips_code'] == '00nan', 'fips_code'] = '00000'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Attach 2 digit state code from state fips code\n",
    "tmp_state = safegraph_ref_data_fips.groupby(['state_fips','state']).size().reset_index().rename(columns={0:'count'})\n",
    "enigma_agg_data['state_fips_ea'] = enigma_agg_data['state_fips_ea'].astype('str').apply(lambda x: x.zfill(2))\n",
    "\n",
    "lefton = ['state_fips_ea']\n",
    "righton = ['state_fips']\n",
    "\n",
    "enigma_agg_data = pd.merge(enigma_agg_data, tmp_state[['state_fips','state']], how='left', left_on=lefton, right_on=righton)\n",
    "\n",
    "enigma_agg_data['state_code'] = enigma_agg_data['state']\n",
    "enigma_agg_data['state_name'] = enigma_agg_data['state_name_ea']\n",
    "\n",
    "enigma_agg_data = enigma_agg_data.drop(columns=['state', 'state_fips'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataframe Shape:  (583062, 14)\n",
      "Number of States:  55\n",
      "Number of Counties:  3211\n",
      "Minimum Date:  2020-01-21 00:00:00\n",
      "Maximum Date:  2020-09-29 00:00:00\n",
      "Duplicate State-Fips-Date:  0\n",
      "Null State Code:  0\n",
      "Null County Code:  0\n",
      "Null Dates:  0\n",
      "Case Control Total:  602329120.0\n",
      "Death Control Total:  22406363.0\n"
     ]
    }
   ],
   "source": [
    "getDataInfo(enigma_agg_data, 'cases_ea', 'deaths_ea')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Enigma Johns Hopkins University"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Download data and basic summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "Enigma Johns Hopkins\n"
     ]
    }
   ],
   "source": [
    "print(\"--------------------\")\n",
    "print(\"Enigma Johns Hopkins\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "enigma_jh_data = getS3Data('covid19-lake', 'enigma-jhu-timeseries/csv/jhu_csse_covid_19_timeseries_merged.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter to only US\n",
    "enigma_jh_data = enigma_jh_data[enigma_jh_data['iso2']=='US']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape:  (419379, 14)\n",
      "Case control total:  62110114.0\n",
      "Death control total:  3522063.0\n"
     ]
    }
   ],
   "source": [
    "enigma_jh_data = dataCleanUp(enigma_jh_data, 'date', 'fips', 'confirmed', 'deaths', '_ejhu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create clean fips_code\n",
    "enigma_jh_data['fips_code'] = enigma_jh_data['fips_ejhu']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add \"Out of XX\" counties to \"Unknown\"\n",
    "jh_unknown_fips_counties = ['Out of AL', 'Out of AK',\n",
    "       'Out of AZ', 'Out of AR', 'Out of CA', 'Out of CO', 'Out of CT',\n",
    "       'Out of DE', 'Out of DC', 'Out of FL', 'Out of GA', 'Out of HI',\n",
    "       'Out of ID', 'Out of IL', 'Out of IN', 'Out of IA', 'Out of KS',\n",
    "       'Out of KY', 'Out of LA', 'Out of ME', 'Out of MD', 'Out of MA',\n",
    "       'Out of MI', 'Out of MN', 'Out of MS', 'Out of MO', 'Out of MT',\n",
    "       'Out of NE', 'Out of NV', 'Out of NH', 'Out of NJ', 'Out of NM',\n",
    "       'Out of NY', 'Out of NC', 'Out of ND', 'Out of OH', 'Out of OK',\n",
    "       'Out of OR', 'Out of PA', 'Out of RI', 'Out of SC', 'Out of SD',\n",
    "       'Out of TN', 'Out of TX', 'Out of UT', 'Out of VT', 'Out of VA',\n",
    "       'Out of WA', 'Out of WV', 'Out of WI', 'Out of WY']\n",
    "enigma_jh_data.loc[enigma_jh_data['admin2_ejhu'].isin(jh_unknown_fips_counties), 'fips_code'] = '00000'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "enigma_jh_data.loc[enigma_jh_data['admin2_ejhu']=='Dukes and Nantucket', 'fips_code'] = 'n0001'\n",
    "enigma_jh_data.loc[enigma_jh_data['admin2_ejhu']=='Kansas City', 'fips_code'] = 'n0002'\n",
    "enigma_jh_data.loc[enigma_jh_data['admin2_ejhu']=='Michigan Department of Corrections (MDOC)', 'fips_code'] = 'n0003'\n",
    "enigma_jh_data.loc[enigma_jh_data['admin2_ejhu']=='Federal Correctional Institution (FCI)','fips_code'] = 'n0004'\n",
    "enigma_jh_data.loc[enigma_jh_data['admin2_ejhu']=='Bear River', 'fips_code'] = 'n0005'\n",
    "enigma_jh_data.loc[enigma_jh_data['admin2_ejhu']=='Central Utah', 'fips_code'] = 'n0006'\n",
    "enigma_jh_data.loc[enigma_jh_data['admin2_ejhu']=='Southeast Utah', 'fips_code'] = 'n0007'\n",
    "enigma_jh_data.loc[enigma_jh_data['admin2_ejhu']=='Southwest Utah', 'fips_code'] = 'n0008'\n",
    "enigma_jh_data.loc[enigma_jh_data['admin2_ejhu']=='TriCounty', 'fips_code'] = 'n0009'\n",
    "enigma_jh_data.loc[enigma_jh_data['admin2_ejhu']=='Weber-Morgan', 'fips_code'] = 'n0010'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "lefton = ['province_state_ejhu']\n",
    "righton = ['state_name']\n",
    "\n",
    "enigma_jh_data = pd.merge(\n",
    "    enigma_jh_data, state_ref_data, \n",
    "    how='left', left_on=lefton, right_on=righton)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "enigma_jh_data.loc[enigma_jh_data['province_state_ejhu']=='Diamond Princess', 'state_code'] = 'CA'\n",
    "enigma_jh_data.loc[enigma_jh_data['province_state_ejhu']=='Grand Princess', 'state_code'] = 'CA'\n",
    "\n",
    "enigma_jh_data.loc[enigma_jh_data['province_state_ejhu']=='Diamond Princess', 'state_name'] = 'California'\n",
    "enigma_jh_data.loc[enigma_jh_data['province_state_ejhu']=='Grand Princess', 'state_name'] = 'California'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "enigma_jh_data['date'] = enigma_jh_data['date_ejhu']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uid_ejhu</th>\n",
       "      <th>fips_ejhu</th>\n",
       "      <th>iso2_ejhu</th>\n",
       "      <th>iso3_ejhu</th>\n",
       "      <th>code3_ejhu</th>\n",
       "      <th>admin2_ejhu</th>\n",
       "      <th>latitude_ejhu</th>\n",
       "      <th>longitude_ejhu</th>\n",
       "      <th>province_state_ejhu</th>\n",
       "      <th>country_region_ejhu</th>\n",
       "      <th>date_ejhu</th>\n",
       "      <th>confirmed_ejhu</th>\n",
       "      <th>deaths_ejhu</th>\n",
       "      <th>recovered_ejhu</th>\n",
       "      <th>date</th>\n",
       "      <th>fips_code</th>\n",
       "      <th>state_name</th>\n",
       "      <th>state_code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>84001001</td>\n",
       "      <td>01001</td>\n",
       "      <td>US</td>\n",
       "      <td>USA</td>\n",
       "      <td>840</td>\n",
       "      <td>Autauga</td>\n",
       "      <td>32.53952745</td>\n",
       "      <td>-86.64408227</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>US</td>\n",
       "      <td>2020-01-22</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020-01-22</td>\n",
       "      <td>01001</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>AL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>84001003</td>\n",
       "      <td>01003</td>\n",
       "      <td>US</td>\n",
       "      <td>USA</td>\n",
       "      <td>840</td>\n",
       "      <td>Baldwin</td>\n",
       "      <td>30.72774991</td>\n",
       "      <td>-87.72207058</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>US</td>\n",
       "      <td>2020-01-22</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020-01-22</td>\n",
       "      <td>01003</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>AL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   uid_ejhu fips_ejhu iso2_ejhu iso3_ejhu code3_ejhu admin2_ejhu  \\\n",
       "0  84001001     01001        US       USA        840     Autauga   \n",
       "1  84001003     01003        US       USA        840     Baldwin   \n",
       "\n",
       "  latitude_ejhu longitude_ejhu province_state_ejhu country_region_ejhu  \\\n",
       "0   32.53952745   -86.64408227             Alabama                  US   \n",
       "1   30.72774991   -87.72207058             Alabama                  US   \n",
       "\n",
       "   date_ejhu  confirmed_ejhu  deaths_ejhu recovered_ejhu       date fips_code  \\\n",
       "0 2020-01-22             0.0          0.0            NaN 2020-01-22     01001   \n",
       "1 2020-01-22             0.0          0.0            NaN 2020-01-22     01003   \n",
       "\n",
       "  state_name state_code  \n",
       "0    Alabama         AL  \n",
       "1    Alabama         AL  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enigma_jh_data.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataframe Shape:  (419379, 18)\n",
      "Number of States:  51\n",
      "Number of Counties:  3201\n",
      "Minimum Date:  2020-01-22 00:00:00\n",
      "Maximum Date:  2020-05-29 00:00:00\n",
      "Duplicate State-Fips-Date:  0\n",
      "Null State Code:  0\n",
      "Null County Code:  0\n",
      "Null Dates:  0\n",
      "Case Control Total:  62110114.0\n",
      "Death Control Total:  3522063.0\n"
     ]
    }
   ],
   "source": [
    "getDataInfo(enigma_jh_data, 'confirmed_ejhu', 'deaths_ejhu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Enigma New York Times"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Download data and clean data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "Enigma New York Times\n"
     ]
    }
   ],
   "source": [
    "print(\"--------------------\")\n",
    "print(\"Enigma New York Times\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get data\n",
    "enigma_nyt_data = getS3Data('covid19-lake', 'enigma-nytimes-data-in-usa/csv/us_county/us_county.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape:  (129747, 6)\n",
      "Case control total:  31616769.0\n",
      "Death control total:  1652495.0\n"
     ]
    }
   ],
   "source": [
    "# Clean up\n",
    "enigma_nyt_data = dataCleanUp(enigma_nyt_data, 'date', 'fips', 'cases','deaths','_enyt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fix Fips codes\n",
    "enigma_nyt_data['fips_code'] = enigma_nyt_data['fips_enyt']\n",
    "enigma_nyt_data.loc[enigma_nyt_data['county_enyt']=='New York City', 'fips_code'] = 'NYC000'\n",
    "enigma_nyt_data.loc[enigma_nyt_data['county_enyt']=='New York City', 'fips_code'] = 'KC0000'\n",
    "enigma_nyt_data.loc[enigma_nyt_data['county_enyt']=='Unknown', 'fips_code'] = '00000'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add state\n",
    "lefton = ['state_enyt']\n",
    "righton = ['state_name']\n",
    "\n",
    "enigma_nyt_data = pd.merge(\n",
    "    enigma_nyt_data, state_ref_data, \n",
    "    how='left', left_on=lefton, right_on=righton)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fix for extra states\n",
    "enigma_nyt_data.loc[enigma_nyt_data['state_enyt']=='Puerto Rico', 'state_code'] = 'PR'\n",
    "enigma_nyt_data.loc[enigma_nyt_data['state_enyt']=='Virgin Islands', 'state_code'] = 'VI'\n",
    "enigma_nyt_data.loc[enigma_nyt_data['state_enyt']=='Guam', 'state_code'] = 'GU'\n",
    "enigma_nyt_data.loc[enigma_nyt_data['state_enyt']=='Northern Mariana Islands', 'state_code'] = 'MP'\n",
    "\n",
    "enigma_nyt_data.loc[enigma_nyt_data['state_enyt']=='Puerto Rico', 'state_name'] = 'Puerto Rico'\n",
    "enigma_nyt_data.loc[enigma_nyt_data['state_enyt']=='Virgin Islands', 'state_name'] = 'Virgin Islands'\n",
    "enigma_nyt_data.loc[enigma_nyt_data['state_enyt']=='Guam', 'state_name'] = 'Guam'\n",
    "enigma_nyt_data.loc[enigma_nyt_data['state_enyt']=='Northern Mariana Islands', 'state_name'] = 'Northern Mariana Islands'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataframe Shape:  (129747, 10)\n",
      "Number of States:  55\n",
      "Number of Counties:  2885\n",
      "Minimum Date:  2020-01-21 00:00:00\n",
      "Maximum Date:  2020-05-09 00:00:00\n",
      "Duplicate State-Fips-Date:  0\n",
      "Null State Code:  0\n",
      "Null County Code:  0\n",
      "Null Dates:  0\n",
      "Case Control Total:  31616769.0\n",
      "Death Control Total:  1652495.0\n"
     ]
    }
   ],
   "source": [
    "getDataInfo(enigma_nyt_data, 'cases_enyt', 'deaths_enyt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rearc New York Times"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Download data and basic summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "Rearc New York Times\n"
     ]
    }
   ],
   "source": [
    "print(\"--------------------\")\n",
    "print(\"Rearc New York Times\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get data\n",
    "rearc_nyt_data = getS3Data('covid19-lake', 'rearc-covid-19-nyt-data-in-usa/csv/us-counties/us-counties.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape:  (975686, 6)\n",
      "Case control total:  2378946443.0\n",
      "Death control total:  57311702.0\n"
     ]
    }
   ],
   "source": [
    "# Clean up\n",
    "rearc_nyt_data = dataCleanUp(rearc_nyt_data, 'date', 'fips', 'cases','deaths','_rnyt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Edit fips codes\n",
    "rearc_nyt_data['fips_code'] = rearc_nyt_data['fips_rnyt']\n",
    "rearc_nyt_data.loc[rearc_nyt_data['county_rnyt']=='New York City', 'fips_code'] = 'NYC000'\n",
    "rearc_nyt_data.loc[rearc_nyt_data['county_rnyt']=='New York City', 'fips_code'] = 'KC0000'\n",
    "rearc_nyt_data.loc[rearc_nyt_data['county_rnyt']=='Unknown', 'fips_code'] = '00000'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Attach state code\n",
    "lefton = ['state_rnyt']\n",
    "righton = ['state_name']\n",
    "\n",
    "rearc_nyt_data = pd.merge(\n",
    "    rearc_nyt_data, state_ref_data, \n",
    "    how='left', left_on=lefton, right_on=righton)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add some states codes and names\n",
    "\n",
    "rearc_nyt_data.loc[rearc_nyt_data['state_rnyt']=='Puerto Rico', 'state_code'] = 'PR'\n",
    "rearc_nyt_data.loc[rearc_nyt_data['state_rnyt']=='Virgin Islands', 'state_code'] = 'VI'\n",
    "rearc_nyt_data.loc[rearc_nyt_data['state_rnyt']=='Guam', 'state_code'] = 'GU'\n",
    "rearc_nyt_data.loc[rearc_nyt_data['state_rnyt']=='Northern Mariana Islands', 'state_code'] = 'MP'\n",
    "\n",
    "rearc_nyt_data.loc[rearc_nyt_data['state_rnyt']=='Puerto Rico', 'state_name'] = 'Puerto Rico'\n",
    "rearc_nyt_data.loc[rearc_nyt_data['state_rnyt']=='Virgin Islands', 'state_name'] = 'Virgin Islands'\n",
    "rearc_nyt_data.loc[rearc_nyt_data['state_rnyt']=='Guam', 'state_name'] = 'Guam'\n",
    "rearc_nyt_data.loc[rearc_nyt_data['state_rnyt']=='Northern Mariana Islands', 'state_name'] = 'Northern Mariana Islands'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataframe Shape:  (975686, 10)\n",
      "Number of States:  55\n",
      "Number of Counties:  3221\n",
      "Minimum Date:  2020-01-21 00:00:00\n",
      "Maximum Date:  2021-01-28 00:00:00\n",
      "Duplicate State-Fips-Date:  0\n",
      "Null State Code:  0\n",
      "Null County Code:  0\n",
      "Null Dates:  0\n",
      "Case Control Total:  2378946443.0\n",
      "Death Control Total:  57311702.0\n"
     ]
    }
   ],
   "source": [
    "getDataInfo(rearc_nyt_data, 'cases_rnyt','deaths_rnyt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### USA Facts (CDC Affiliate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Download data and basic summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "USA Facts - CDC\n"
     ]
    }
   ],
   "source": [
    "print(\"--------------------\")\n",
    "print(\"USA Facts - CDC\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the data\n",
    "url=\"https://usafactsstatic.blob.core.windows.net/public/data/covid-19/covid_confirmed_usafacts.csv\"\n",
    "data_confirmed = pd.read_csv(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the data\n",
    "url = \"https://usafactsstatic.blob.core.windows.net/public/data/covid-19/covid_deaths_usafacts.csv\"\n",
    "data_deaths = pd.read_csv(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the data\n",
    "url = \"https://usafactsstatic.blob.core.windows.net/public/data/covid-19/covid_county_population_usafacts.csv\"\n",
    "data_county_pop = pd.read_csv(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Move the date column headers into a single column as rows\n",
    "data_confirmed = data_confirmed.melt(\n",
    "    id_vars=['countyFIPS','County Name','State','stateFIPS'], \n",
    "    var_name='Date', value_name='Confirmed')\n",
    "\n",
    "data_deaths = data_deaths.melt(\n",
    "    id_vars=['countyFIPS','County Name','State','stateFIPS'], \n",
    "    var_name='Date', value_name='Deaths')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join the raw tables together\n",
    "\n",
    "# Part 1\n",
    "lefton = ['countyFIPS', 'County Name', 'State', 'stateFIPS', 'Date']\n",
    "righton = ['countyFIPS', 'County Name', 'State', 'stateFIPS', 'Date']\n",
    "\n",
    "data = pd.merge(data_confirmed, data_deaths, how='left', left_on=lefton, right_on=righton)\n",
    "\n",
    "# Part 2\n",
    "lefton = ['countyFIPS', 'County Name', 'State']\n",
    "righton = ['countyFIPS', 'County Name', 'State']\n",
    "\n",
    "usafacts_cdc_data = pd.merge(data, data_county_pop, how='left', left_on=lefton, right_on=righton)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape:  (1191735, 8)\n",
      "Case control total:  2339714800.0\n",
      "Death control total:  56405847.0\n"
     ]
    }
   ],
   "source": [
    "# Clean up\n",
    "usafacts_cdc_data = dataCleanUp(usafacts_cdc_data, 'Date', 'countyFIPS', 'Confirmed','Deaths','_cdc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fips code clean up\n",
    "usafacts_cdc_data['fips_code'] = usafacts_cdc_data['countyfips_cdc']\n",
    "usafacts_cdc_data.loc[(usafacts_cdc_data['county name_cdc']=='Grand Princess Cruise Ship'), 'fips_code'] = '99999'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# State code\n",
    "usafacts_cdc_data['state_code'] = usafacts_cdc_data['state_cdc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Attach State Name\n",
    "lefton = ['state_code']\n",
    "righton = ['state_code']\n",
    "\n",
    "usafacts_cdc_data = pd.merge(\n",
    "    usafacts_cdc_data, state_ref_data, \n",
    "    how='left', left_on=lefton, right_on=righton)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataframe Shape:  (1191735, 12)\n",
      "Number of States:  51\n",
      "Number of Counties:  3146\n",
      "Minimum Date:  2020-01-22 00:00:00\n",
      "Maximum Date:  2021-01-28 00:00:00\n",
      "Duplicate State-Fips-Date:  0\n",
      "Null State Code:  0\n",
      "Null County Code:  0\n",
      "Null Dates:  0\n",
      "Case Control Total:  2339714800.0\n",
      "Death Control Total:  56405847.0\n"
     ]
    }
   ],
   "source": [
    "getDataInfo(usafacts_cdc_data, 'confirmed_cdc','deaths_cdc')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Google Mobility Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Download data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "Google Mobility\n"
     ]
    }
   ],
   "source": [
    "print(\"--------------------\")\n",
    "print(\"Google Mobility\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get data\n",
    "url = \"https://www.gstatic.com/covid19/mobility/Global_Mobility_Report.csv\"\n",
    "data = pd.read_csv(url, dtype=str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean up\n",
    "data = data[data['country_region_code'] == 'US']\n",
    "data['date'] = data['date'].astype('datetime64')\n",
    "google_data = data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### State Level Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create state table\n",
    "google_state_data = google_data[\n",
    "    (google_data['sub_region_1'].notnull()) &\n",
    "    (~google_data['sub_region_2'].notnull())\n",
    "]\n",
    "google_state_data = google_state_data.add_suffix(\"_goog_st\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add state_code\n",
    "lefton = ['sub_region_1_goog_st']\n",
    "righton = ['state_name']\n",
    "\n",
    "google_state_data = pd.merge(\n",
    "    google_state_data, state_ref_data, \n",
    "    how='left', left_on=lefton, right_on=righton)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop columns not needed\n",
    "google_state_data['date'] = google_state_data['date_goog_st']\n",
    "google_state_data = google_state_data.drop(columns=\n",
    "                                             ['country_region_code_goog_st',\n",
    "                                              'country_region_goog_st', 'sub_region_1_goog_st','sub_region_2_goog_st',\n",
    "                                              'date_goog_st','state_name'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### County Level Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create county table\n",
    "google_county_data = google_data[\n",
    "    (google_data['sub_region_1'].notnull()) &\n",
    "    (google_data['sub_region_2'].notnull())\n",
    "]\n",
    "google_county_data = google_county_data.add_suffix(\"_goog_cnty\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add state code\n",
    "lefton = ['sub_region_1_goog_cnty']\n",
    "righton = ['state_name']\n",
    "\n",
    "google_county_data = pd.merge(\n",
    "    google_county_data, state_ref_data, \n",
    "    how='left', left_on=lefton, right_on=righton)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create state_county concatenation\n",
    "google_county_data['state_county'] = google_county_data['state_code'] + google_county_data['sub_region_2_goog_cnty']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manual state-county name fixes\n",
    "google_county_data.loc[google_county_data['state_county']=='AKAnchorage', 'state_county'] = 'AKAnchorage Municipality'\n",
    "google_county_data.loc[google_county_data['state_county']=='AKBethel', 'state_county'] = 'AKBethel Census Area'\n",
    "google_county_data.loc[google_county_data['state_county']=='AKFairbanks North Star', 'state_county'] = 'AKFairbanks North Star Borough'\n",
    "google_county_data.loc[google_county_data['state_county']=='AKJuneau', 'state_county'] = 'AKJuneau City and Borough'\n",
    "google_county_data.loc[google_county_data['state_county']=='AKKetchikan Gateway', 'state_county'] = 'AKKetchikan Gateway Borough'\n",
    "google_county_data.loc[google_county_data['state_county']=='AKKodiak Island', 'state_county'] = 'AKKodiak Island Borough'\n",
    "google_county_data.loc[google_county_data['state_county']=='AKMatanuska-Susitna', 'state_county'] = 'AKMatanuska-Susitna Borough'\n",
    "google_county_data.loc[google_county_data['state_county']=='AKNorth Slope', 'state_county'] = 'AKNorth Slope Borough'\n",
    "google_county_data.loc[google_county_data['state_county']=='AKSitka', 'state_county'] = 'AKSitka City and Borough'\n",
    "google_county_data.loc[google_county_data['state_county']=='AKSoutheast Fairbanks', 'state_county'] = 'AKSoutheast Fairbanks Census Area'\n",
    "google_county_data.loc[google_county_data['state_county']=='AKValdez-Cordova', 'state_county'] = 'AKValdez-Cordova Census Area'\n",
    "google_county_data.loc[google_county_data['state_county']=='MDBaltimore', 'state_county'] = 'MDBaltimore city'\n",
    "\n",
    "google_county_data.loc[google_county_data['state_county']=='MOSt. Louis', 'state_county'] = 'MOSt. Louis city'\n",
    "google_county_data.loc[google_county_data['state_county']=='NMDo√±a Ana County', 'state_county'] = 'NMDona Ana County'\n",
    "google_county_data.loc[google_county_data['state_county']=='VAAlexandria', 'state_county'] = 'VAAlexandria city'\n",
    "google_county_data.loc[google_county_data['state_county']=='VABristol', 'state_county'] = 'VABristol city'\n",
    "google_county_data.loc[google_county_data['state_county']=='VABuena Vista', 'state_county'] = 'VABuena Vista city'\n",
    "google_county_data.loc[google_county_data['state_county']=='VACharlottesville', 'state_county'] = 'VACharlottesville city'\n",
    "google_county_data.loc[google_county_data['state_county']=='VAChesapeake', 'state_county'] = 'VAChesapeake city'\n",
    "google_county_data.loc[google_county_data['state_county']=='VAColonial Heights', 'state_county'] = 'VAColonial Heights city'\n",
    "google_county_data.loc[google_county_data['state_county']=='VACovington', 'state_county'] = 'VACovington city'\n",
    "\n",
    "google_county_data.loc[google_county_data['state_county']=='VADanville', 'state_county'] = 'VADanville city'\n",
    "google_county_data.loc[google_county_data['state_county']=='VAEmporia', 'state_county'] = 'VAEmporia city'\n",
    "google_county_data.loc[google_county_data['state_county']=='VAFairfax', 'state_county'] = 'VAFairfax city'\n",
    "google_county_data.loc[google_county_data['state_county']=='VAFalls Church', 'state_county'] = 'VAFalls Church city'\n",
    "google_county_data.loc[google_county_data['state_county']=='VAFranklin', 'state_county'] = 'VAFranklin city'\n",
    "google_county_data.loc[google_county_data['state_county']=='VAFredericksburg', 'state_county'] = 'VAFredericksburg city'\n",
    "google_county_data.loc[google_county_data['state_county']=='VAGalax', 'state_county'] = 'VAGalax city'\n",
    "google_county_data.loc[google_county_data['state_county']=='VAHampton', 'state_county'] = 'VAHampton city'\n",
    "google_county_data.loc[google_county_data['state_county']=='VAHarrisonburg', 'state_county'] = 'VAHarrisonburg city'\n",
    "google_county_data.loc[google_county_data['state_county']=='VAHopewell', 'state_county'] = 'VAHopewell city'\n",
    "\n",
    "google_county_data.loc[google_county_data['state_county']=='VALexington', 'state_county'] = 'VALexington city'\n",
    "google_county_data.loc[google_county_data['state_county']=='VALynchburg', 'state_county'] = 'VALynchburg city'\n",
    "google_county_data.loc[google_county_data['state_county']=='VAManassas', 'state_county'] = 'VAManassas city'\n",
    "google_county_data.loc[google_county_data['state_county']=='VAManassas Park', 'state_county'] = 'VAManassas Park city'\n",
    "google_county_data.loc[google_county_data['state_county']=='VAMartinsville', 'state_county'] = 'VAMartinsville city'\n",
    "google_county_data.loc[google_county_data['state_county']=='VANewport News', 'state_county'] = 'VANewport News city'\n",
    "google_county_data.loc[google_county_data['state_county']=='VANorfolk', 'state_county'] = 'VANorfolk city'\n",
    "google_county_data.loc[google_county_data['state_county']=='VANorton', 'state_county'] = 'VANorton city'\n",
    "google_county_data.loc[google_county_data['state_county']=='VAPetersburg', 'state_county'] = 'VAPetersburg city'\n",
    "google_county_data.loc[google_county_data['state_county']=='VAPoquoson', 'state_county'] = 'VAPoquoson city'\n",
    "google_county_data.loc[google_county_data['state_county']=='VAPortsmouth', 'state_county'] = 'VAPortsmouth city'\n",
    "google_county_data.loc[google_county_data['state_county']=='VARadford', 'state_county'] = 'VARadford city'\n",
    "google_county_data.loc[google_county_data['state_county']=='VARichmond', 'state_county'] = 'VARichmond city'\n",
    "google_county_data.loc[google_county_data['state_county']=='VARoanoke', 'state_county'] = 'VARoanoke city'\n",
    "\n",
    "google_county_data.loc[google_county_data['state_county']=='VASalem', 'state_county'] = 'VASalem city'\n",
    "google_county_data.loc[google_county_data['state_county']=='VAStaunton', 'state_county'] = 'VAStaunton city'\n",
    "google_county_data.loc[google_county_data['state_county']=='VASuffolk', 'state_county'] = 'VASuffolk city'\n",
    "google_county_data.loc[google_county_data['state_county']=='VAVirginia Beach', 'state_county'] = 'VAVirginia Beach city'\n",
    "google_county_data.loc[google_county_data['state_county']=='VAWaynesboro', 'state_county'] = 'VAWaynesboro city'\n",
    "google_county_data.loc[google_county_data['state_county']=='VAWilliamsburg', 'state_county'] = 'VAWilliamsburg city'\n",
    "google_county_data.loc[google_county_data['state_county']=='VAWinchester', 'state_county'] = 'VAWinchester city'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Attach FIPS code\n",
    "lefton = ['state_county']\n",
    "righton = ['state_county']\n",
    "\n",
    "google_county_data = pd.merge(\n",
    "    google_county_data, safegraph_ref_data_fips, \n",
    "    how='left', left_on=lefton, right_on=righton)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create fips_code and data columns\n",
    "google_county_data['fips_code'] = google_county_data['fips']\n",
    "google_county_data['date'] = google_county_data['date_goog_cnty']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['AKNome', 'SDOglala Lakota County']"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# List counties which did not get a fips code\n",
    "list(google_county_data[google_county_data.fips.isnull()]['state_county'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add missing county manually\n",
    "google_county_data.loc[google_county_data['state_county']=='SDOglala Lakota County', 'fips_code'] = 'SDOGL'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop columns not needed\n",
    "google_county_data = google_county_data.drop(columns=['country_region_code_goog_cnty',\n",
    "       'country_region_goog_cnty', 'sub_region_1_goog_cnty',\n",
    "      'date_goog_cnty','state_name',\n",
    "       'state_county', 'state', 'state_fips', 'county_fips', 'county',\n",
    "       'class_code', 'fips'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combine Data Sources"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "Joining Data\n"
     ]
    }
   ],
   "source": [
    "print(\"--------------------\")\n",
    "print(\"Joining Data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a list of tables to join\n",
    "raw_data_list = [\n",
    "    enigma_agg_data,\n",
    "    enigma_jh_data,\n",
    "    enigma_nyt_data,\n",
    "    rearc_nyt_data,\n",
    "    usafacts_cdc_data\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since we want the sum columns to have different names, put them in a list\n",
    "sum_cols = [\n",
    "    ['cases_ea', 'deaths_ea'],\n",
    "    ['confirmed_ejhu', 'deaths_ejhu'],\n",
    "    ['cases_enyt', 'deaths_enyt'],\n",
    "    ['cases_rnyt', 'deaths_rnyt'],\n",
    "    ['confirmed_cdc', 'deaths_cdc']\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recursively group the tables and put that in a new list\n",
    "grouped_data_list = []\n",
    "for data, sum_col in zip(raw_data_list, sum_cols):\n",
    "    data = data.groupby(['state_code','fips_code', 'date'])[sum_col].agg('sum').reset_index()\n",
    "    grouped_data_list.append(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add google mobility county data\n",
    "grouped_data_list.append(\n",
    "    google_county_data\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join all the tables together\n",
    "on_col = ['state_code', 'fips_code', 'date']\n",
    "covid_data = pd.DataFrame(columns=on_col)\n",
    "for data in grouped_data_list:\n",
    "    covid_data = pd.merge(\n",
    "        covid_data, data, how='outer', left_on=on_col, right_on=on_col\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add google mobility state data\n",
    "on_col = ['state_code', 'date']\n",
    "covid_data = covid_data = pd.merge(covid_data, google_state_data, how='left', left_on=on_col, right_on=on_col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attach County Name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create county name lookup table from all data used so far\n",
    "cols = [\n",
    "    ['county_name_ea'],\n",
    "    ['admin2_ejhu'],\n",
    "    ['county_enyt'],\n",
    "    ['county_rnyt'],\n",
    "    ['county name_cdc'],\n",
    "    ['sub_region_2_goog_cnty']  \n",
    "]\n",
    "\n",
    "raw_data_list = [\n",
    "    enigma_agg_data,\n",
    "    enigma_jh_data,\n",
    "    enigma_nyt_data,\n",
    "    rearc_nyt_data,\n",
    "    usafacts_cdc_data,\n",
    "    google_county_data\n",
    "]\n",
    "\n",
    "county_data_list = []\n",
    "for data, col in zip(raw_data_list, cols):\n",
    "    data = data.groupby(['state_code','fips_code','date']+col).size().reset_index().drop(columns=[0])\n",
    "    data = data.rename(columns={col[0]:\"county_name\"})\n",
    "    county_data_list.append(data)\n",
    "data = pd.concat(county_data_list).dropna(subset=['county_name']).drop(columns=['date'])\n",
    "data = data.drop_duplicates(subset=['state_code','fips_code'], keep=\"first\").reset_index(drop=True)\n",
    "county_names = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Attach county name\n",
    "on_col = ['state_code', 'fips_code']\n",
    "covid_data = pd.merge(covid_data, county_names, how='left', left_on=on_col, right_on=on_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Attach land area\n",
    "on_col = ['fips_code']\n",
    "covid_data = pd.merge(covid_data, safegraph_land, how='left', left_on=on_col, right_on=on_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop extra google county name columns\n",
    "covid_data = covid_data.drop(columns=['sub_region_2_goog_cnty'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attach Lat and Long"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create lat long lookup table\n",
    "lat_long_data = enigma_agg_data.groupby(['state_code','fips_code','lat_ea','long_ea']).size().reset_index().drop(columns=[0])\n",
    "lat_long_data = lat_long_data.dropna(subset=['lat_ea','long_ea'])\n",
    "lat_long_data = lat_long_data.drop_duplicates(subset=['state_code','fips_code'], keep=\"first\").reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join lat long data\n",
    "on_col = ['state_code', 'fips_code']\n",
    "covid_data = pd.merge(covid_data, lat_long_data, how='left', left_on=on_col, right_on=on_col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attach Safegraph Census Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join safegraph census data\n",
    "covid_data = pd.merge(covid_data, safegraph_census_data, how='outer', left_on='fips_code', right_on='fips_code')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createMobilityChange(df, cols_to_average, rolling_ave, new_col_name):\n",
    "    for col in cols_to_average:\n",
    "        df.loc[:, col] = df[col].astype(float)\n",
    "    df[new_col_name] = df[cols_to_average].mean(axis=1).rolling(window=7).mean()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def addFeatures(df):\n",
    "    df['pop_density'] = df['pop_total'] / df['amount_land']\n",
    "    df['deaths_per_100k'] = df['deaths_cdc'] / df['pop_total'] * 100000\n",
    "    df['pir_200_plus_pct'] = df['pir_200_plus'] / df['pir_total']\n",
    "    df['pir_150_plus_pct'] = (df['pir_150_184'] + df['pir_185_199'] + df['pir_200_plus']) / df['pir_total']\n",
    "    df['unins_pct'] = (df['unins_0_18'] + df['unins_18_34'] + df['unins_35_64'] + df['unins_65_plus'])/df['unins_total']\n",
    "    df['hi_75_plus_pct'] = (df['hi_75_99'] + df['hi_100_124'] + df['hi_125_149'] + df['hi_150_199']+ df['hi_200_plus'])/df['hi_total']\n",
    "    df['hi_100_plus_pct'] = (df['hi_100_124'] + df['hi_125_149'] + df['hi_150_199']+ df['hi_200_plus'])/df['hi_total']\n",
    "    df['hi_150_plus_pct'] = (df['hi_125_149'] + df['hi_150_199']+ df['hi_200_plus'])/df['hi_total']\n",
    "    df['e_bach_plus_pct'] = (df['e_bach'] + df['e_mast'] + df['e_prof'] + df['e_doct'])/df['e_total']\n",
    "    df['e_mast_plus_pct'] = (df['e_mast'] + df['e_prof'] + df['e_doct'])/df['e_total']\n",
    "    df['r_white_pct'] = df['r_white'] / df['r_total']\n",
    "    df['r_black_pct'] = df['r_black'] / df['r_total']\n",
    "    df['r_native_pct'] = df['r_native'] / df['r_total']\n",
    "    df['r_asian_pct'] = df['r_asian'] / df['r_total']\n",
    "    df['age_55_plus_pct'] = (\n",
    "        (df['m_55_59']+df['m_60_61']+df['m_62_64']+df['m_65_66']+df['m_67_69']+df['m_70_74']\n",
    "         +df['m_75_79']+df['m_80_84']+df['m_85_110']) +\n",
    "         (df['f_55_59']+df['f_60_61']+df['f_62_64']+df['f_65_66']+df['f_67_69']+df['f_70_74']\n",
    "         +df['f_75_79']+df['f_80_84']+df['f_85_110']))/ (df['m_total'] + df['f_total'])\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def addPercentiles(df, percentile_cols):\n",
    "    data = df\n",
    "    data_list = []\n",
    "    states = list(df.state_code.unique())\n",
    "    for state in states:\n",
    "        cols = []\n",
    "        df = addFeatures(data)\n",
    "        df = df[df.state_code == state]\n",
    "        df = df.dropna(subset=['pop_total']).drop_duplicates(subset=['state_code','fips_code']).drop(columns=['date'])\n",
    "        for percentile_col in percentile_cols:\n",
    "            df = df.sort_values(by=[percentile_col])\n",
    "            df['cum_pop_total'] = df['pop_total'].cumsum()\n",
    "            df[percentile_col + '_percentile'] = df['cum_pop_total'] / df['pop_total'].sum()\n",
    "        cols = [col + '_percentile' for col in percentile_cols]\n",
    "        cols = ['state_code','fips_code'] + cols\n",
    "        df = df[cols]\n",
    "        data_list.append(df)\n",
    "    df = pd.concat(data_list)\n",
    "    data = pd.merge(data, df, how='left', left_on=['state_code','fips_code'], right_on=['state_code','fips_code'])\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the mobility change column as the average of retail and work spaces\n",
    "cols_to_average = ['retail_and_recreation_percent_change_from_baseline_goog_cnty',\n",
    "                   'workplaces_percent_change_from_baseline_goog_cnty']\n",
    "covid_data = createMobilityChange(covid_data, cols_to_average, 14, 'mobility_change_cnty')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Attach percentile columns\n",
    "percentile_cols = ['p_c_i', 'pop_density','pir_200_plus_pct', 'pir_150_plus_pct', 'unins_pct',\n",
    "                  'hi_75_plus_pct', 'hi_100_plus_pct', 'hi_150_plus_pct', 'e_bach_plus_pct', 'e_mast_plus_pct',\n",
    "                   'r_white_pct','r_black_pct', 'r_native_pct', 'r_asian_pct','age_55_plus_pct']\n",
    "covid_data = addPercentiles(covid_data, percentile_cols)\n",
    "\n",
    "# Add low and high percentile columns\n",
    "covid_data['pir_grp'] = [0 if x < 0.5 else 1 for x in covid_data['pir_200_plus_pct_percentile']]\n",
    "covid_data['unins_grp'] = [0 if x < 0.5 else 1 for x in covid_data['unins_pct_percentile']]\n",
    "covid_data['pop_density_grp'] = [0 if x < 0.5 else 1 for x in covid_data['pop_density_percentile']] \n",
    "covid_data['e_grp'] = [0 if x < 0.5 else 1 for x in covid_data['e_bach_plus_pct_percentile']] \n",
    "covid_data['r_b_grp'] = [0 if x < 0.5 else 1 for x in covid_data['r_black_pct_percentile']] \n",
    "covid_data['r_w_grp'] = [0 if x < 0.5 else 1 for x in covid_data['r_white_pct_percentile']]\n",
    "covid_data['age_55_plus_grp'] = [0 if x < 0.5 else 1 for x in covid_data['age_55_plus_pct_percentile']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save Master Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "Saving data to covid_data.p\n"
     ]
    }
   ],
   "source": [
    "print(\"--------------------\")\n",
    "print(\"Saving data to covid_data.p\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('covid_data.p', 'wb') as f:\n",
    "    pickle.dump(covid_data, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state_code</th>\n",
       "      <th>fips_code</th>\n",
       "      <th>date</th>\n",
       "      <th>cases_ea</th>\n",
       "      <th>deaths_ea</th>\n",
       "      <th>confirmed_ejhu</th>\n",
       "      <th>deaths_ejhu</th>\n",
       "      <th>cases_enyt</th>\n",
       "      <th>deaths_enyt</th>\n",
       "      <th>cases_rnyt</th>\n",
       "      <th>...</th>\n",
       "      <th>r_native_pct_percentile</th>\n",
       "      <th>r_asian_pct_percentile</th>\n",
       "      <th>age_55_plus_pct_percentile</th>\n",
       "      <th>pir_grp</th>\n",
       "      <th>unins_grp</th>\n",
       "      <th>pop_density_grp</th>\n",
       "      <th>e_grp</th>\n",
       "      <th>r_b_grp</th>\n",
       "      <th>r_w_grp</th>\n",
       "      <th>age_55_plus_grp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AK</td>\n",
       "      <td>00000</td>\n",
       "      <td>2020-04-02</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AK</td>\n",
       "      <td>00000</td>\n",
       "      <td>2020-04-08</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows √ó 212 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  state_code fips_code       date  cases_ea  deaths_ea  confirmed_ejhu  \\\n",
       "0         AK     00000 2020-04-02       1.0        0.0             0.0   \n",
       "1         AK     00000 2020-04-08       1.0        0.0             0.0   \n",
       "\n",
       "   deaths_ejhu  cases_enyt  deaths_enyt  cases_rnyt  ...  \\\n",
       "0          0.0         1.0          0.0         1.0  ...   \n",
       "1          0.0         1.0          0.0         1.0  ...   \n",
       "\n",
       "   r_native_pct_percentile  r_asian_pct_percentile  \\\n",
       "0                      NaN                     NaN   \n",
       "1                      NaN                     NaN   \n",
       "\n",
       "   age_55_plus_pct_percentile pir_grp unins_grp pop_density_grp  e_grp  \\\n",
       "0                         NaN       1         1               1      1   \n",
       "1                         NaN       1         1               1      1   \n",
       "\n",
       "  r_b_grp r_w_grp age_55_plus_grp  \n",
       "0       1       1               1  \n",
       "1       1       1               1  \n",
       "\n",
       "[2 rows x 212 columns]"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "covid_data.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Control Totals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "Control Totals\n"
     ]
    }
   ],
   "source": [
    "print(\"--------------------\")\n",
    "print(\"Control Totals\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "Census Data\n"
     ]
    }
   ],
   "source": [
    "print(\"--------------------\")\n",
    "print(\"Census Data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-7782.0"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Safegraph census data control\n",
    "covid_data[covid_data['date']=='2020-05-10'].pop_total.sum() + covid_data[covid_data['date'].isnull()].pop_total.sum() - safegraph_census_data.pop_total.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "Cases\n"
     ]
    }
   ],
   "source": [
    "print(\"--------------------\")\n",
    "print(\"Cases\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "print(enigma_agg_data.cases_ea.sum() - covid_data.cases_ea.sum())\n",
    "print(enigma_jh_data.confirmed_ejhu.sum() - covid_data.confirmed_ejhu.sum())\n",
    "print(enigma_nyt_data.cases_enyt.sum() - covid_data.cases_enyt.sum())\n",
    "print(rearc_nyt_data.cases_rnyt.sum() - covid_data.cases_rnyt.sum())\n",
    "print(usafacts_cdc_data.confirmed_cdc.sum() - covid_data.confirmed_cdc.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "Deaths\n"
     ]
    }
   ],
   "source": [
    "print(\"--------------------\")\n",
    "print(\"Deaths\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "print(enigma_agg_data.deaths_ea.sum() - covid_data.deaths_ea.sum())\n",
    "print(enigma_jh_data.deaths_ejhu.sum() - covid_data.deaths_ejhu.sum())\n",
    "print(enigma_nyt_data.deaths_enyt.sum() - covid_data.deaths_enyt.sum())\n",
    "print(rearc_nyt_data.deaths_rnyt.sum() - covid_data.deaths_rnyt.sum())\n",
    "print(usafacts_cdc_data.deaths_cdc.sum() - covid_data.deaths_cdc.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
